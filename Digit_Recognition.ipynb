{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "cXNvdPotQ-5z",
        "outputId": "d3c9dc5f-58af-4993-a9f8-0cb7732802e5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision.tranforms'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb3636f7bfef>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.tranforms'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.tranforms import ToTensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "#data_train\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "#test_data\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imrvlGZYRji4",
        "outputId": "18984e09-27e1-4902-ad71-cfa5b7b90bc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 18393833.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 488566.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4489931.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5039822.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpwSTC3cSWJW",
        "outputId": "b848eec1-1720-4ed2-fa25-c1392341f77a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "p2M56qkdS0wt",
        "outputId": "55fcbcef-78fb-4b80-bb6c-d47621f4b64a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c49bad44360a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DJIm_2t8S8dq",
        "outputId": "c7743272-31c8-497e-f25a-ca7c7fd75bda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader = {\n",
        "    'train': DataLoader(train_data, batch_size = 100, shuffle = True, num_workers=1),\n",
        "    'test': DataLoader(test_data, batch_size = 100, shuffle = True, num_workers = 1)\n",
        "}"
      ],
      "metadata": {
        "id": "bby_iZ9OTQ2P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-zs_oeOTm_5",
        "outputId": "b7ee810e-06c8-4328-9c10-440550289ff4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7cd68879f4c0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7cd68879ed10>}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "IVqVmKj5Tsfa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(CNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEBZQh8XZaf1",
        "outputId": "2fd3c85a-efe4-42ab-a356-e892cc7d474e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'type'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#định nghĩa model CNN\n",
        "class CNN(nn.Module) :\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2 ))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training = self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.softmax(x)"
      ],
      "metadata": {
        "id": "ygPAgg8bUKC7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(isinstance(CNN, type))  # Should print True\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx2T3oHBZCKy",
        "outputId": "a1f35b13-e27f-4238-c84e-13b2949d3d68"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_index, (data, target) in enumerate(loader['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_index % 25 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(loader[\"train\"].dataset)} ({100. * batch_index / len(loader[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in loader['test']:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.data.max(1, keepdim = True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "\n",
        "    test_loss /= len(loader['test'].dataset)\n",
        "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loader[\"test\"].dataset)} ({100. * correct / len(loader[\"test\"].dataset):.0f}%)\\n')"
      ],
      "metadata": {
        "id": "vlJV_KQAVucy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "  train(epoch)\n",
        "  test()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtaZ02fSZ4AO",
        "outputId": "47d5e682-865f-4fdc-b30c-ea7e6b1aa966"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-77188f16b16c>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303987\n",
            "Train Epoch: 1 [2500/60000 (4%)]\tLoss: 2.287505\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.144826\n",
            "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 1.908900\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.917684\n",
            "Train Epoch: 1 [12500/60000 (21%)]\tLoss: 1.786554\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.765240\n",
            "Train Epoch: 1 [17500/60000 (29%)]\tLoss: 1.804622\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.717485\n",
            "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 1.753507\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 1.683703\n",
            "Train Epoch: 1 [27500/60000 (46%)]\tLoss: 1.796128\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.713228\n",
            "Train Epoch: 1 [32500/60000 (54%)]\tLoss: 1.703750\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 1.604105\n",
            "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 1.786479\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.708931\n",
            "Train Epoch: 1 [42500/60000 (71%)]\tLoss: 1.688117\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 1.672920\n",
            "Train Epoch: 1 [47500/60000 (79%)]\tLoss: 1.734883\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.719828\n",
            "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 1.673131\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 1.611578\n",
            "Train Epoch: 1 [57500/60000 (96%)]\tLoss: 1.669308\n",
            "Test set: Average loss: 0.0161, Accuracy: 8518/10000 (85%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.621311\n",
            "Train Epoch: 2 [2500/60000 (4%)]\tLoss: 1.708640\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 1.666354\n",
            "Train Epoch: 2 [7500/60000 (12%)]\tLoss: 1.607099\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.666527\n",
            "Train Epoch: 2 [12500/60000 (21%)]\tLoss: 1.653153\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 1.663242\n",
            "Train Epoch: 2 [17500/60000 (29%)]\tLoss: 1.597321\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.645062\n",
            "Train Epoch: 2 [22500/60000 (38%)]\tLoss: 1.739481\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 1.676245\n",
            "Train Epoch: 2 [27500/60000 (46%)]\tLoss: 1.615307\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.637236\n",
            "Train Epoch: 2 [32500/60000 (54%)]\tLoss: 1.652695\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 1.584875\n",
            "Train Epoch: 2 [37500/60000 (62%)]\tLoss: 1.632884\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.686396\n",
            "Train Epoch: 2 [42500/60000 (71%)]\tLoss: 1.608382\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 1.633090\n",
            "Train Epoch: 2 [47500/60000 (79%)]\tLoss: 1.625224\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.602347\n",
            "Train Epoch: 2 [52500/60000 (88%)]\tLoss: 1.628436\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 1.574959\n",
            "Train Epoch: 2 [57500/60000 (96%)]\tLoss: 1.594288\n",
            "Test set: Average loss: 0.0152, Accuracy: 9473/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.609932\n",
            "Train Epoch: 3 [2500/60000 (4%)]\tLoss: 1.607083\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 1.569240\n",
            "Train Epoch: 3 [7500/60000 (12%)]\tLoss: 1.533673\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.619155\n",
            "Train Epoch: 3 [12500/60000 (21%)]\tLoss: 1.624277\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 1.586373\n",
            "Train Epoch: 3 [17500/60000 (29%)]\tLoss: 1.514568\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.536492\n",
            "Train Epoch: 3 [22500/60000 (38%)]\tLoss: 1.554810\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 1.544187\n",
            "Train Epoch: 3 [27500/60000 (46%)]\tLoss: 1.531833\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.572115\n",
            "Train Epoch: 3 [32500/60000 (54%)]\tLoss: 1.577546\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 1.572769\n",
            "Train Epoch: 3 [37500/60000 (62%)]\tLoss: 1.557876\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.531305\n",
            "Train Epoch: 3 [42500/60000 (71%)]\tLoss: 1.545210\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 1.512960\n",
            "Train Epoch: 3 [47500/60000 (79%)]\tLoss: 1.582582\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.565783\n",
            "Train Epoch: 3 [52500/60000 (88%)]\tLoss: 1.574480\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 1.598882\n",
            "Train Epoch: 3 [57500/60000 (96%)]\tLoss: 1.581966\n",
            "Test set: Average loss: 0.0150, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.535933\n",
            "Train Epoch: 4 [2500/60000 (4%)]\tLoss: 1.526790\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 1.547908\n",
            "Train Epoch: 4 [7500/60000 (12%)]\tLoss: 1.549915\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.551211\n",
            "Train Epoch: 4 [12500/60000 (21%)]\tLoss: 1.494820\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 1.605507\n",
            "Train Epoch: 4 [17500/60000 (29%)]\tLoss: 1.550894\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.594974\n",
            "Train Epoch: 4 [22500/60000 (38%)]\tLoss: 1.593373\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 1.533844\n",
            "Train Epoch: 4 [27500/60000 (46%)]\tLoss: 1.543422\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.492682\n",
            "Train Epoch: 4 [32500/60000 (54%)]\tLoss: 1.561158\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 1.551712\n",
            "Train Epoch: 4 [37500/60000 (62%)]\tLoss: 1.599320\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.540205\n",
            "Train Epoch: 4 [42500/60000 (71%)]\tLoss: 1.567984\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 1.484293\n",
            "Train Epoch: 4 [47500/60000 (79%)]\tLoss: 1.508867\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.530487\n",
            "Train Epoch: 4 [52500/60000 (88%)]\tLoss: 1.509960\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 1.527272\n",
            "Train Epoch: 4 [57500/60000 (96%)]\tLoss: 1.592672\n",
            "Test set: Average loss: 0.0150, Accuracy: 9615/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.513896\n",
            "Train Epoch: 5 [2500/60000 (4%)]\tLoss: 1.592327\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 1.578513\n",
            "Train Epoch: 5 [7500/60000 (12%)]\tLoss: 1.519566\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.559514\n",
            "Train Epoch: 5 [12500/60000 (21%)]\tLoss: 1.586490\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 1.516266\n",
            "Train Epoch: 5 [17500/60000 (29%)]\tLoss: 1.552807\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.513227\n",
            "Train Epoch: 5 [22500/60000 (38%)]\tLoss: 1.534593\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 1.547276\n",
            "Train Epoch: 5 [27500/60000 (46%)]\tLoss: 1.512560\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.560646\n",
            "Train Epoch: 5 [32500/60000 (54%)]\tLoss: 1.532605\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 1.574394\n",
            "Train Epoch: 5 [37500/60000 (62%)]\tLoss: 1.522195\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.568009\n",
            "Train Epoch: 5 [42500/60000 (71%)]\tLoss: 1.533256\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 1.514377\n",
            "Train Epoch: 5 [47500/60000 (79%)]\tLoss: 1.554192\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.538758\n",
            "Train Epoch: 5 [52500/60000 (88%)]\tLoss: 1.537035\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 1.544340\n",
            "Train Epoch: 5 [57500/60000 (96%)]\tLoss: 1.557772\n",
            "Test set: Average loss: 0.0149, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.561761\n",
            "Train Epoch: 6 [2500/60000 (4%)]\tLoss: 1.537029\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 1.529492\n",
            "Train Epoch: 6 [7500/60000 (12%)]\tLoss: 1.567845\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.566411\n",
            "Train Epoch: 6 [12500/60000 (21%)]\tLoss: 1.496504\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 1.538292\n",
            "Train Epoch: 6 [17500/60000 (29%)]\tLoss: 1.570241\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.511776\n",
            "Train Epoch: 6 [22500/60000 (38%)]\tLoss: 1.531909\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 1.497131\n",
            "Train Epoch: 6 [27500/60000 (46%)]\tLoss: 1.516307\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.522548\n",
            "Train Epoch: 6 [32500/60000 (54%)]\tLoss: 1.512828\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 1.600893\n",
            "Train Epoch: 6 [37500/60000 (62%)]\tLoss: 1.548702\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.602908\n",
            "Train Epoch: 6 [42500/60000 (71%)]\tLoss: 1.579889\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 1.531493\n",
            "Train Epoch: 6 [47500/60000 (79%)]\tLoss: 1.541800\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.587902\n",
            "Train Epoch: 6 [52500/60000 (88%)]\tLoss: 1.508806\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 1.544024\n",
            "Train Epoch: 6 [57500/60000 (96%)]\tLoss: 1.529795\n",
            "Test set: Average loss: 0.0149, Accuracy: 9691/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.534623\n",
            "Train Epoch: 7 [2500/60000 (4%)]\tLoss: 1.532367\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 1.565355\n",
            "Train Epoch: 7 [7500/60000 (12%)]\tLoss: 1.534091\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.502668\n",
            "Train Epoch: 7 [12500/60000 (21%)]\tLoss: 1.532996\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 1.517173\n",
            "Train Epoch: 7 [17500/60000 (29%)]\tLoss: 1.518452\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.523086\n",
            "Train Epoch: 7 [22500/60000 (38%)]\tLoss: 1.514880\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 1.512539\n",
            "Train Epoch: 7 [27500/60000 (46%)]\tLoss: 1.534028\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.523358\n",
            "Train Epoch: 7 [32500/60000 (54%)]\tLoss: 1.503978\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 1.538856\n",
            "Train Epoch: 7 [37500/60000 (62%)]\tLoss: 1.536576\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.546406\n",
            "Train Epoch: 7 [42500/60000 (71%)]\tLoss: 1.558161\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 1.489402\n",
            "Train Epoch: 7 [47500/60000 (79%)]\tLoss: 1.564487\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.504612\n",
            "Train Epoch: 7 [52500/60000 (88%)]\tLoss: 1.573311\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 1.543761\n",
            "Train Epoch: 7 [57500/60000 (96%)]\tLoss: 1.553763\n",
            "Test set: Average loss: 0.0149, Accuracy: 9713/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.494263\n",
            "Train Epoch: 8 [2500/60000 (4%)]\tLoss: 1.516466\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 1.502948\n",
            "Train Epoch: 8 [7500/60000 (12%)]\tLoss: 1.515007\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.550822\n",
            "Train Epoch: 8 [12500/60000 (21%)]\tLoss: 1.531767\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 1.524626\n",
            "Train Epoch: 8 [17500/60000 (29%)]\tLoss: 1.534321\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.525139\n",
            "Train Epoch: 8 [22500/60000 (38%)]\tLoss: 1.526422\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 1.543543\n",
            "Train Epoch: 8 [27500/60000 (46%)]\tLoss: 1.519747\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.551248\n",
            "Train Epoch: 8 [32500/60000 (54%)]\tLoss: 1.544693\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 1.534125\n",
            "Train Epoch: 8 [37500/60000 (62%)]\tLoss: 1.503722\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.549247\n",
            "Train Epoch: 8 [42500/60000 (71%)]\tLoss: 1.495598\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 1.529609\n",
            "Train Epoch: 8 [47500/60000 (79%)]\tLoss: 1.487821\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.517618\n",
            "Train Epoch: 8 [52500/60000 (88%)]\tLoss: 1.558531\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 1.503295\n",
            "Train Epoch: 8 [57500/60000 (96%)]\tLoss: 1.549581\n",
            "Test set: Average loss: 0.0149, Accuracy: 9737/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.515814\n",
            "Train Epoch: 9 [2500/60000 (4%)]\tLoss: 1.540481\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 1.506641\n",
            "Train Epoch: 9 [7500/60000 (12%)]\tLoss: 1.535008\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.511810\n",
            "Train Epoch: 9 [12500/60000 (21%)]\tLoss: 1.497030\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 1.503943\n",
            "Train Epoch: 9 [17500/60000 (29%)]\tLoss: 1.545922\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.539736\n",
            "Train Epoch: 9 [22500/60000 (38%)]\tLoss: 1.574154\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 1.498327\n",
            "Train Epoch: 9 [27500/60000 (46%)]\tLoss: 1.541157\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.538851\n",
            "Train Epoch: 9 [32500/60000 (54%)]\tLoss: 1.536822\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 1.535054\n",
            "Train Epoch: 9 [37500/60000 (62%)]\tLoss: 1.554660\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.519739\n",
            "Train Epoch: 9 [42500/60000 (71%)]\tLoss: 1.567241\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 1.493972\n",
            "Train Epoch: 9 [47500/60000 (79%)]\tLoss: 1.526805\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.594717\n",
            "Train Epoch: 9 [52500/60000 (88%)]\tLoss: 1.487545\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 1.562237\n",
            "Train Epoch: 9 [57500/60000 (96%)]\tLoss: 1.545647\n",
            "Test set: Average loss: 0.0149, Accuracy: 9741/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "data, target = test_data[5]\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim = 1, keepdim = True)\n",
        "print(f'Prediction: {prediction.item()}, Actual: {target}')\n",
        "\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "plt.imshow(image, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "YhBApppKanVZ",
        "outputId": "f4fd78a3-a558-49f3-8f48-fb25d8865e42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 1, Actual: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-77188f16b16c>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ20lEQVR4nO3df0zU9x3H8RdYPbWFc4BwUH8UtdWlKsusMmrL7CQiW4y/tmjtH7o0Gh02U9Z2YV213ZawuWTrujjtH4usW7WtycTVbGwWC2Yd2IAaY7YRIWxgFJwm3CEKMvjsD9Nbr4L28I43h89H8knk7vvl3vvuG5/9cueXOOecEwAAQyzeegAAwL2JAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP3WQ/waX19fbpw4YISEhIUFxdnPQ4AIEzOOXV0dCgjI0Px8QNf5wy7AF24cEGTJ0+2HgMAcJdaWlo0adKkAZ8fdj+CS0hIsB4BABABd/r7PGoB2r17tx566CGNHTtW2dnZ+uijjz7TfvzYDQBGhjv9fR6VAL3zzjsqKirSzp07dfLkSWVlZSk/P1+XLl2KxssBAGKRi4IFCxa4wsLC4Ne9vb0uIyPDlZSU3HFfv9/vJLFYLBYrxpff77/t3/cRvwK6ceOG6urqlJeXF3wsPj5eeXl5qq6uvmX77u5uBQKBkAUAGPkiHqDLly+rt7dXaWlpIY+npaWptbX1lu1LSkrk9XqDi0/AAcC9wfxTcMXFxfL7/cHV0tJiPRIAYAhE/N8BpaSkaNSoUWprawt5vK2tTT6f75btPR6PPB5PpMcAAAxzEb8CGjNmjObNm6eKiorgY319faqoqFBOTk6kXw4AEKOicieEoqIirV+/Xo899pgWLFig1157TZ2dnfrmN78ZjZcDAMSgqARozZo1+s9//qMdO3aotbVVX/jCF1ReXn7LBxMAAPeuOOecsx7ikwKBgLxer/UYAIC75Pf7lZiYOODz5p+CAwDcmwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT91kPACB6li1bNqj9/vCHP4S9z9atW8PeZ+/evWHv09vbG/Y+GJ64AgIAmCBAAAATEQ/QK6+8ori4uJA1a9asSL8MACDGReU9oEcffVTvv//+/1/kPt5qAgCEikoZ7rvvPvl8vmh8awDACBGV94DOnTunjIwMTZs2Tc8884yam5sH3La7u1uBQCBkAQBGvogHKDs7W6WlpSovL9eePXvU1NSkJ598Uh0dHf1uX1JSIq/XG1yTJ0+O9EgAgGEo4gEqKCjQN77xDc2dO1f5+fn64x//qPb2dr377rv9bl9cXCy/3x9cLS0tkR4JADAMRf3TARMmTNAjjzyihoaGfp/3eDzyeDzRHgMAMMxE/d8BXb16VY2NjUpPT4/2SwEAYkjEA/T888+rqqpK//rXv/S3v/1NK1eu1KhRo/T0009H+qUAADEs4j+CO3/+vJ5++mlduXJFEydO1BNPPKGamhpNnDgx0i8FAIhhcc45Zz3EJwUCAXm9XusxgGEnOTk57H1Onz49qNeaNGnSoPYL1/jx48Pe5/r161GYBNHg9/uVmJg44PPcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBH1X0gHIDJyc3PD3meobioqSQcOHAh7n66urihMgljBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDdswIDH4wl7n5deeikKk0TOb3/727D3cc5FYRLECq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUMDBnzpyw95k3b14UJunff//737D3+dOf/hSFSTCScQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqSAgdWrV1uPcFt/+ctfrEfAPYArIACACQIEADARdoCOHz+uZcuWKSMjQ3FxcSorKwt53jmnHTt2KD09XePGjVNeXp7OnTsXqXkBACNE2AHq7OxUVlaWdu/e3e/zu3bt0uuvv669e/fqxIkTuv/++5Wfn6+urq67HhYAMHKE/SGEgoICFRQU9Pucc06vvfaavv/972v58uWSpDfffFNpaWkqKyvT2rVr725aAMCIEdH3gJqamtTa2qq8vLzgY16vV9nZ2aquru53n+7ubgUCgZAFABj5Ihqg1tZWSVJaWlrI42lpacHnPq2kpERerze4Jk+eHMmRAADDlPmn4IqLi+X3+4OrpaXFeiQAwBCIaIB8Pp8kqa2tLeTxtra24HOf5vF4lJiYGLIAACNfRAOUmZkpn8+nioqK4GOBQEAnTpxQTk5OJF8KABDjwv4U3NWrV9XQ0BD8uqmpSadPn1ZSUpKmTJmibdu26Uc/+pEefvhhZWZm6uWXX1ZGRoZWrFgRybkBADEu7ADV1tbqqaeeCn5dVFQkSVq/fr1KS0v14osvqrOzU5s2bVJ7e7ueeOIJlZeXa+zYsZGbGgAQ8+Kcc856iE8KBALyer3WYwBR9eGHH4a9z+OPPx72Pjdu3Ah7H0nKzs4Oe5/Tp08P6rUwcvn9/tu+r2/+KTgAwL2JAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJsL+dQwAQg3mLtWD2WcwOjs7B7Ufd7bGUOAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1Igbs0f/586xEGtGfPHusRgAFxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpMBdeuyxx4bkddrb28Peh5uRYjjjCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIFPeOKJJ8LeZ926dVGY5FZ+vz/sfc6fPx+FSYDI4AoIAGCCAAEATIQdoOPHj2vZsmXKyMhQXFycysrKQp7fsGGD4uLiQtbSpUsjNS8AYIQIO0CdnZ3KysrS7t27B9xm6dKlunjxYnAdOHDgroYEAIw8YX8IoaCgQAUFBbfdxuPxyOfzDXooAMDIF5X3gCorK5WamqqZM2dqy5YtunLlyoDbdnd3KxAIhCwAwMgX8QAtXbpUb775pioqKvSTn/xEVVVVKigoUG9vb7/bl5SUyOv1BtfkyZMjPRIAYBiK+L8DWrt2bfDPc+bM0dy5czV9+nRVVlZq8eLFt2xfXFysoqKi4NeBQIAIAcA9IOofw542bZpSUlLU0NDQ7/Mej0eJiYkhCwAw8kU9QOfPn9eVK1eUnp4e7ZcCAMSQsH8Ed/Xq1ZCrmaamJp0+fVpJSUlKSkrSq6++qtWrV8vn86mxsVEvvviiZsyYofz8/IgODgCIbWEHqLa2Vk899VTw64/fv1m/fr327NmjM2fO6De/+Y3a29uVkZGhJUuW6Ic//KE8Hk/kpgYAxLywA7Ro0SI55wZ8/s9//vNdDQRYSk5ODnuf+PihuaPV0aNHh+R1gKHCveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuK/khuIZV//+teH5HXa29vD3ueNN96I/CCAIa6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUI9KkSZMGtd+6desiPEn/zp8/H/Y+tbW1UZgEsMMVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRYkR6/PHHB7VffPzQ/DdZWVnZkLwOMJxxBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpBiRkpOTh+y1Ll++HPY+v/jFL6IwCRBbuAICAJggQAAAE2EFqKSkRPPnz1dCQoJSU1O1YsUK1dfXh2zT1dWlwsJCJScn64EHHtDq1avV1tYW0aEBALEvrABVVVWpsLBQNTU1Onr0qHp6erRkyRJ1dnYGt9m+fbvee+89HTx4UFVVVbpw4YJWrVoV8cEBALEtrA8hlJeXh3xdWlqq1NRU1dXVKTc3V36/X7/+9a+1f/9+feUrX5Ek7du3T5///OdVU1OjL33pS5GbHAAQ0+7qPSC/3y9JSkpKkiTV1dWpp6dHeXl5wW1mzZqlKVOmqLq6ut/v0d3drUAgELIAACPfoAPU19enbdu2aeHChZo9e7YkqbW1VWPGjNGECRNCtk1LS1Nra2u/36ekpERerze4Jk+ePNiRAAAxZNABKiws1NmzZ/X222/f1QDFxcXy+/3B1dLSclffDwAQGwb1D1G3bt2qI0eO6Pjx45o0aVLwcZ/Ppxs3bqi9vT3kKqitrU0+n6/f7+XxeOTxeAYzBgAghoV1BeSc09atW3Xo0CEdO3ZMmZmZIc/PmzdPo0ePVkVFRfCx+vp6NTc3KycnJzITAwBGhLCugAoLC7V//34dPnxYCQkJwfd1vF6vxo0bJ6/Xq2effVZFRUVKSkpSYmKinnvuOeXk5PAJOABAiLACtGfPHknSokWLQh7ft2+fNmzYIEn6+c9/rvj4eK1evVrd3d3Kz8/Xr371q4gMCwAYOeKcc856iE8KBALyer3WYyDGlZWVDWq/5cuXh73PyZMnw95nMD8R6OnpCXsfwJLf71diYuKAz3MvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJgY1G9EBYbS6NGjw95n+vTpUZikf11dXWHvw52tAa6AAABGCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUw15fX1/Y+9TW1g7qtWbPnh32Pg0NDYN6LeBexxUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5Fi2Ovt7Q17n5deemlQr+WcC3ufurq6Qb0WcK/jCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHnBnP3xSgKBALyer3WYwAA7pLf71diYuKAz3MFBAAwQYAAACbCClBJSYnmz5+vhIQEpaamasWKFaqvrw/ZZtGiRYqLiwtZmzdvjujQAIDYF1aAqqqqVFhYqJqaGh09elQ9PT1asmSJOjs7Q7bbuHGjLl68GFy7du2K6NAAgNgX1m9ELS8vD/m6tLRUqampqqurU25ubvDx8ePHy+fzRWZCAMCIdFfvAfn9fklSUlJSyONvvfWWUlJSNHv2bBUXF+vatWsDfo/u7m4FAoGQBQC4B7hB6u3tdV/72tfcwoULQx5/4403XHl5uTtz5oz73e9+5x588EG3cuXKAb/Pzp07nSQWi8VijbDl9/tv25FBB2jz5s1u6tSprqWl5bbbVVRUOEmuoaGh3+e7urqc3+8PrpaWFvODxmKxWKy7X3cKUFjvAX1s69atOnLkiI4fP65Jkybddtvs7GxJUkNDg6ZPn37L8x6PRx6PZzBjAABiWFgBcs7pueee06FDh1RZWanMzMw77nP69GlJUnp6+qAGBACMTGEFqLCwUPv379fhw4eVkJCg1tZWSZLX69W4cePU2Nio/fv366tf/aqSk5N15swZbd++Xbm5uZo7d25U/gcAAGJUOO/7aICf8+3bt88551xzc7PLzc11SUlJzuPxuBkzZrgXXnjhjj8H/CS/32/+c0sWi8Vi3f2609/93IwUABAV3IwUADAsESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMDLsAOeesRwAARMCd/j4fdgHq6OiwHgEAEAF3+vs8zg2zS46+vj5duHBBCQkJiouLC3kuEAho8uTJamlpUWJiotGE9jgON3EcbuI43MRxuGk4HAfnnDo6OpSRkaH4+IGvc+4bwpk+k/j4eE2aNOm22yQmJt7TJ9jHOA43cRxu4jjcxHG4yfo4eL3eO24z7H4EBwC4NxAgAICJmAqQx+PRzp075fF4rEcxxXG4ieNwE8fhJo7DTbF0HIbdhxAAAPeGmLoCAgCMHAQIAGCCAAEATBAgAICJmAnQ7t279dBDD2ns2LHKzs7WRx99ZD3SkHvllVcUFxcXsmbNmmU9VtQdP35cy5YtU0ZGhuLi4lRWVhbyvHNOO3bsUHp6usaNG6e8vDydO3fOZtgoutNx2LBhwy3nx9KlS22GjZKSkhLNnz9fCQkJSk1N1YoVK1RfXx+yTVdXlwoLC5WcnKwHHnhAq1evVltbm9HE0fFZjsOiRYtuOR82b95sNHH/YiJA77zzjoqKirRz506dPHlSWVlZys/P16VLl6xHG3KPPvqoLl68GFx//etfrUeKus7OTmVlZWn37t39Pr9r1y69/vrr2rt3r06cOKH7779f+fn56urqGuJJo+tOx0GSli5dGnJ+HDhwYAgnjL6qqioVFhaqpqZGR48eVU9Pj5YsWaLOzs7gNtu3b9d7772ngwcPqqqqShcuXNCqVasMp468z3IcJGnjxo0h58OuXbuMJh6AiwELFixwhYWFwa97e3tdRkaGKykpMZxq6O3cudNlZWVZj2FKkjt06FDw676+Pufz+dxPf/rT4GPt7e3O4/G4AwcOGEw4ND59HJxzbv369W758uUm81i5dOmSk+Sqqqqcczf/vx89erQ7ePBgcJt//OMfTpKrrq62GjPqPn0cnHPuy1/+svv2t79tN9RnMOyvgG7cuKG6ujrl5eUFH4uPj1deXp6qq6sNJ7Nx7tw5ZWRkaNq0aXrmmWfU3NxsPZKppqYmtba2hpwfXq9X2dnZ9+T5UVlZqdTUVM2cOVNbtmzRlStXrEeKKr/fL0lKSkqSJNXV1amnpyfkfJg1a5amTJkyos+HTx+Hj7311ltKSUnR7NmzVVxcrGvXrlmMN6BhdzPST7t8+bJ6e3uVlpYW8nhaWpr++c9/Gk1lIzs7W6WlpZo5c6YuXryoV199VU8++aTOnj2rhIQE6/FMtLa2SlK/58fHz90rli5dqlWrVikzM1ONjY363ve+p4KCAlVXV2vUqFHW40VcX1+ftm3bpoULF2r27NmSbp4PY8aM0YQJE0K2HcnnQ3/HQZLWrVunqVOnKiMjQ2fOnNF3v/td1dfX6/e//73htKGGfYDwfwUFBcE/z507V9nZ2Zo6dareffddPfvss4aTYThYu3Zt8M9z5szR3LlzNX36dFVWVmrx4sWGk0VHYWGhzp49e0+8D3o7Ax2HTZs2Bf88Z84cpaena/HixWpsbNT06dOHesx+DfsfwaWkpGjUqFG3fIqlra1NPp/PaKrhYcKECXrkkUfU0NBgPYqZj88Bzo9bTZs2TSkpKSPy/Ni6dauOHDmiDz74IOTXt/h8Pt24cUPt7e0h24/U82Gg49Cf7OxsSRpW58OwD9CYMWM0b948VVRUBB/r6+tTRUWFcnJyDCezd/XqVTU2Nio9Pd16FDOZmZny+Xwh50cgENCJEyfu+fPj/PnzunLlyog6P5xz2rp1qw4dOqRjx44pMzMz5Pl58+Zp9OjRIedDfX29mpubR9T5cKfj0J/Tp09L0vA6H6w/BfFZvP32287j8bjS0lL397//3W3atMlNmDDBtba2Wo82pL7zne+4yspK19TU5D788EOXl5fnUlJS3KVLl6xHi6qOjg536tQpd+rUKSfJ/exnP3OnTp1y//73v51zzv34xz92EyZMcIcPH3Znzpxxy5cvd5mZme769evGk0fW7Y5DR0eHe/755111dbVrampy77//vvviF7/oHn74YdfV1WU9esRs2bLFeb1eV1lZ6S5evBhc165dC26zefNmN2XKFHfs2DFXW1vrcnJyXE5OjuHUkXen49DQ0OB+8IMfuNraWtfU1OQOHz7spk2b5nJzc40nDxUTAXLOuV/+8pduypQpbsyYMW7BggWupqbGeqQht2bNGpeenu7GjBnjHnzwQbdmzRrX0NBgPVbUffDBB07SLWv9+vXOuZsfxX755ZddWlqa83g8bvHixa6+vt526Ci43XG4du2aW7JkiZs4caIbPXq0mzp1qtu4ceOI+4+0/v73S3L79u0LbnP9+nX3rW99y33uc59z48ePdytXrnQXL160GzoK7nQcmpubXW5urktKSnIej8fNmDHDvfDCC87v99sO/in8OgYAgIlh/x4QAGBkIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM/A+ZiUOBZyjn+wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}